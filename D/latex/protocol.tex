\documentclass{scrartcl}
\input{header.tex}



\begin{document}

\begin{titlepage}\centering
\textsc{\Large Institute For Nonlinear Dynamics \\[1.5ex] Universität Göttingen}

\vspace*{2cm}
{\huge A Practical Course On Network Science}
\vspace*{2cm}

\rule{\textwidth}{1pt}\\[0.5cm]
{\bfseries \huge Block D: \\[0.5cm] \huge \bfseries Additional Topics\\[0.5cm]}
\rule{\textwidth}{1pt}

\vspace*{4cm}

\begin{Large}\begin{tabular}{rl}
        \textbf{Participants:}  & Erik Schultheis                                \\    
                   & \textit{erik.schultheis@stud.uni-goettingen.de}\\[0.5cm]
                   & Thomas Staudt                                  \\
                   & \textit{thomas.staudt@stud.uni-goettingen.de}  \\[1.0cm]

       \textbf{Tutors:}        & Xiaozhu Zhang, Nora Molkenthin, Benjamin Schäfer, \\
                               & Malte Schröder                                    \\[1.0cm]
       \textbf{Deadline:}      & 28.07.2015
\end{tabular}\end{Large}

\vspace*{1.5cm}


\end{titlepage}

\tableofcontents
\clearpage

\section{Epidemics on Networks}
\label{sec:eponnet}
We consider an epidemic model in which each node is always in exactly one of the states \emph{susceptible}, \emph{infected} or \emph{recovered}. 
In every timestep, each infected node infects susceptible neighbours with probability $\beta$ and each infected node recovers with probability $\gamma$. 
The first five timesteps of evolving these dynamics on a BA network of $N=50$ nodes and $k=3$ are shown in figure \ref{fig:D11}.

If all nodes connected to a susceptible node recover before they infect it, that node will never become infected (upper left node in figure \ref{fig:D11}). How likely this is to happen depends on the infection and recovery probabilities $\beta$ and $\gamma$. 
It therefore seems sensible to define $q$ as the percentage of nodes that ever were infected (i.e., not necessarily at the same time). 
It can be calculated by simulating the network dynamics until there are no more infected nodes and is then given by the percentage of recovered nodes. 

The results are shown in figure \ref{fig:D12}. 
It turns out that in the model evaluated, the chance that the whole 
population gets infected rises quite fast if the infectiousness surpasses
a certain critical value, and then more slowly approaches $1$. It is also 
notable that for $\beta > 0.6$, more than $90\%$ get infected even if
the recovery rate is at an extremely high value of $95\%$.

From these results, one can conclude that, to contain the spread of a disease following the SIR model, 
it is much more important to reduce infections of susceptible individuals than to heal already ill ones.

The average number of new infections a node can cause is $\beta \left< k \right>$, whereas it can only heal itself. A good guess for a disease spread parameter could therefore be 
\begin{align}
 s = \frac{\beta \left< k\right>}{\gamma}.
\end{align}
...

To investigate the world wide spread of an epidemic in more detail, we now switch to a continuous model. At each node, there is a percentage of infected $j_n$ and susceptible $s_n$ at a node $n$, which is evolved by
\begin{align}
\partial_t j_n &=& \overbrace{\alpha s_n j_n \sigma( j_n / \epsilon)}^{\text{local spread}} &&- \overbrace{\beta j_n}^{\text{recovery}} &+ \overbrace{\sum{\gamma P_mn (j_m - j_n)}}^{\text{network spread}}&\\
\partial_t s_n &=& -\alpha s_n j_n \sigma( j_n / \epsilon)&  &&- \sum{\gamma P_mn (j_m - j_n)}&.
\end{align}
The first term describes how the disease spreads at one location (i.e. proportional to both susceptible and infected individuals, if $j_n > \epsilon$), the second describes the recovery with rate $\beta$ and the third how infected individuals travel from one node to another. Since each infected was susceptible before, the dgl for the susceptible contains the same terms except the recovery, but with an overall minus sign.

To characterize the spread of the epidemic, the time when there are more than $\epsilon$ infected for the first time, called the \emph{arrival time} $T_A(n) = \mathrm{min}_t \sigma(j_n / \epsilon) \neq 0$ of the disease, is determiend for each node. Since the geographical distance has (in this model) no direct influence on how fast a disease can be transmitted from one country to the next, an \emph{effective distance} based on passenger flux is introduced. It is defined by
\begin{align}
	d_{mn} = 1 - \ln (P_mn).
\end{align}

In figure \ref{} \textbf{a)} and \textbf{b)}, the amount of infected individuals $j_n$ is plotted for times $t_1=$, $t_2 = $. Subfigure \textbf{c)} shows arrival times for all countries.

To find the origin of the outbreak just by using the spread data, we look at the plots of arrival time vs. path length (with resprect to effective distance) to a potential outbreak source. 
Ideally, this would yield a linear relation for the actual outbreak source, and no correlation at all for any other country. In practice, the graphs of neighbouring countries look alike. 
Furthermore, the linearity between distance and time is only a trend, the data contain a lot of fluctuations.
Still, this allows to restrict the possible outbreak sources to a few countries. One could then look which one is most closely neighboured to the other possible source countries to find the most likely origin candidate.

In the simulated presented here, it is easily possible to determine that out of South Africa, Peru, and Indonesia, only South Africa can be the epidemic's origin, as shown by figure \ref{}.
\begin{figure}
    \centering
    \def\svgwidth{0.9\textwidth}
    \input{D1_.pdf_tex}
    \caption{Initial state of a $N=50, k=3$ Barabasi-Albert network with a single infected individual, and time developmen according to the discrete SIR model describen in section \ref{sec:eponnet}. In this example, all but one node have been infected during the spread of the disease. The last remaining node can no longer be infected, because all of its neighbours are already recovered.}
    \label{fig:D11}
\end{figure}

\begin{figure}
    \centering
    \gnuplotloadfile[terminal=epslatex, terminaloptions={color size 5,2.0}]{evint.plt}
    \caption{Percentage of nodes that were infected at some time during the disease spread, 
		depending on the contagiosity $\beta$ for different recovery rates $\gamma$. Note that 
		even instant recovery $\gamma=1$ cannot prevent the spread of extremly contagious diseases
		in this model, because a node cannot recover in the same timestep it was infected.}
    \label{fig:D12}
\end{figure}


\clearpage
\section{Inferring Network Structure}
The phrase \enquote{if you want to understand function, study structure}
uttered by Francis Crick is a common credo in biochemistry, applied
successfully to analyze and understand the function of large molecules. For
networks too, their structure, meaning the topology and the weigth
distributions, determine what the network can and can't do. This section's
task is to reverse this idea in a certain way: What can be deduced about
the structure of a network when having access to (some of) the output it
produces?

\subsection{Reconstructing Small Networks with Kuramoto Dynamics}
The approach used in order to reconstruct networks with oscillatory
Kuramoto dynamics can be found in the uploaded instruction and the
formulation of the task. The notation used in the following also coincides
with the notation of the instruction, if not introduced elsewise. The
pseudo inverse matrix was calculated with the function
\texttt{numpy.linalg.pinv()} provided by the \texttt{numpy} library.
The most important remarks regarding the simulation and the obtained
results are:
\begin{itemize}
    \item The integration time step for the Euler integration of the
        Kuramoto dynamic was $\dif t = 0.01$.
    \item Linearly spaced values $(T\ix{i})\ix{i=0}\Ix{M+2} \subset [0,
        T\ix{max}]$ were used as sample times. $M+2$ sample times had to be
        used in order to calculate the approximate derivatives for the border values. 
    \item The quality of the reconstructed adjacency matrix $\bar{K}$
        compared to the original matrix $K$ was measured by the quantity $Q_{95}$
        that was also used in a figure of the handout. It is defined
        in the publication of M. Timme and J. Casadiego, J. Phys. A: Math.
        Theor. 47 343001 (2014).
    \item The quality measures $\bar{Q}_{95}$ given below for one set $(N,
        M, T\ix{max})$ of parameters are the averaged $Q_{95}$ values for
        10000 trials.
\end{itemize}

The obtained results for different combinations of $(N, M, T\ix{max})$ are
presented and visualized in figure \ref{fig:D211}. The reconstructions
obtained for $N = 5$ have a good quality that is confirmed by both the high
$Q_{95}$ values and the given visualizations, where the difference networks
have few and thin edges. As expected, higher values of $M$ potentially
increase the quality while lower values decrease it.

The reconstruction quality is visibly worse for $N = 10$ while the values
of $Q_{95} \approx 0.40$ for $M = 100$ and $T = 2$ as well as
$Q_{95}\approx 0.8$ for $M = 200$ and $T = 4$ again indicate that more
measurements improve the result visibly.


\subsection{Reconstructing Larger Networks}
When trying to reconstruct larger networks, the applied method in the
considered parameter space seems to get increasingly unsuitable. While for
$N=12$ and  $M = 100, T\ix{max} = 2$ the average quality was around
$\bar{Q}_{95}\approx 0.35$ it dropped to values lower then $0.3$ for even
higher $N$. One can, however, apparently increase the reconstruction
quality by taking more measurements (possibly over a longer period of
time): For example, $N=12, M=200$, and $T\ix{max}=4$ yields
$\bar{Q}_{95}\approx 0.59$. Nevertheless, the quality could not be
arbitrarily improved with higher values for $M$ and/or $T\ix{max}$ in our
attempts and in fact never really got much higher than $0.6$.  
% N = 5, T = 2, M = 100 -> Q_ = 0.94
% N = 5, T = 4, M = 150 -> Q_ = 0.96
% N = 5, T = 3, M = 50  -> Q_ = 0.92

% N = 10, 


\begin{figure}
    \centering
    \def\svgwidth{0.75\textwidth}
    \input{D211.pdf_tex}
    \caption{Reconstruction of oscillating networks with Kuramoto dynamics. The
        value $Q_{95}$ denotes the quality of the trial depicted in the
        respective row, while $\bar{Q}_{95}$ is the quality of 10000
        trials with the same $N, T$, and $M$ averaged. The line widths of
        the edges are proportional to the respective weights and the
        difference graph (last column) was obtained by taking the
        difference $|\omega\ix{orig} - \omega\ix{rec}|$ as weight matrix.}
    \label{fig:D211}
\end{figure}


%The dependencies of the reconstruction quality $Q_{95}$ on the parameters $N, M,$ and
%$T\ix{max}$ are presented in figures \ref{fig:??} to \ref{fig:??}.

%\paragraph{Dependency on $N$:}
%\paragraph{Dependency on $M$:}
%\paragraph{Dependency on $T\ix{max}$:}

\clearpage
\setcounter{section}{3}
\section{Continuative Topics}
\subsection{Balance in Social Networks}
In the following the \emph{social balance model} with \emph{local triad
dynamics} (described on the handout for D4.1) with $p = 1/3$ is applied on
a network that supposedly represents the family structure of Romeo's and
Juliet's families, presented in figure \ref{fig:D41} (a).  (According to
our research, Juliet has no living siblings at the time the drama takes
place, and Romeo never had siblings at all.)

Some exemplary simulation results are given in figure \ref{fig:D41} (b),
(c), and (d).
An obvious and quite frequent result was the one depicted in figure \ref{fig:D41}
(b), meaning that Romeo and Juliet turned into foes while the family
internals remained untouched.  One could also observe that the family
structures got broken up and mixed sometimes, building two new fractions
(figure \ref{fig:D41} (c)). An event that was very rare (see the results for
$P\ix{paradies}$ below) was the complete conciliation of all persons,
figure \ref{fig:D41} (d).

Having applied the local triad algorithm with $p = 1/3$ for $10000$ trials
yielded that the probability $P\ix{love}$ of Romeo and Juliet still being together after
the social balance has been established is $P\ix{love} = 0.2488\%$.
The probability of paradise, $P\ix{paradies}$, was $P\ix{paradies} = 0.0013$.

The dependency of $P\ix{love}$ and $P\ix{paradies}$ on the pattern
selection probability $p$ is shown in figure \ref{fig:D412}. One can
see that the both probabilities increase with increasing $p$, which is
of course expected.





\begin{figure}
    \centering
    \def\svgwidth{0.9\textwidth}
    \input{D41.pdf_tex}
    \caption{Depiction of some typical situations (b, c, d) that arise when
        balancing the original Romeo and Juliet graph (a). The red nodes
        represent Juliet's family (including Juliet herself, marked by J.) and
        the blue nodes consist of Romeo's family (Romeo being marked by
        R.). If an edge is depicted, the corresponding persons are friends;
        if an edge is missing the two corresponding persons are foes. The
        colors of the edges in situation (c) mark the two disjoint fully
        connected components that emerge.}
    \label{fig:D41}
\end{figure}



\end{document}

