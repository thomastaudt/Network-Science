\documentclass{scrartcl}
\input{header.tex}



\begin{document}

\begin{titlepage}\centering
\textsc{\Large Institute For Nonlinear Dynamics \\[1.5ex] Universität Göttingen}

\vspace*{2cm}
{\huge A Practical Course On Network Science}
\vspace*{2cm}

\rule{\textwidth}{1pt}\\[0.5cm]
{\bfseries \huge Block D: \\[0.5cm] \huge \bfseries Additional Topics\\[0.5cm]}
\rule{\textwidth}{1pt}

\vspace*{4cm}

\begin{Large}\begin{tabular}{rl}
        \textbf{Participants:}  & Erik Schultheis                                \\    
                   & \textit{erik.schultheis@stud.uni-goettingen.de}\\[0.5cm]
                   & Thomas Staudt                                  \\
                   & \textit{thomas.staudt@stud.uni-goettingen.de}  \\[1.0cm]

       \textbf{Tutors:}        & Xiaozhu Zhang, Nora Molkenthin, Benjamin Schäfer, \\
                               & Malte Schröder                                    \\[1.0cm]
       \textbf{Deadline:}      & 28.07.2015
\end{tabular}\end{Large}

\vspace*{1.5cm}


\end{titlepage}

\tableofcontents
\clearpage

\section{Epidemics on Networks}
\label{sec:eponnet}
We consider an epidemic model on a network in which each node is always in exactly one of the states \emph{susceptible}, \emph{infected} or \emph{recovered}. 
In every timestep, each infected node infects susceptible neighbours with probability $\beta$ and recovers with probability $\gamma$. 
The first five timesteps of evolving these dynamics on a BA network of $N=50$ nodes and $k=3$ are shown in figure \ref{fig:D11}.

If all nodes connected to a susceptible node recover before they infect it, that node will never become infected (upper left node in figure \ref{fig:D11}). How likely this is to happen depends on the infection and recovery probabilities $\beta$ and $\gamma$. 
One therefore defines $q$ as the percentage of nodes that ever were infected (i.e. not necessarily at the same time). 
It can be calculated by simulating the network dynamics until there are no more infected nodes and is then given by the percentage of recovered nodes. 

The results are shown in figure \ref{fig:D12}. 
It turns out that in the model evaluated, the chance that the whole 
population gets infected rises quite fast if the infectiousness surpasses
a certain critical value, and then more slowly approaches $1$. It is also 
notable that for an infection rate of $\beta > 0.6$, more than $90\%$ get infected even if
the recovery rate is at an extremely high value of $95\%$.

From these results, one can conclude that, to contain the spread of a disease following the SIR model, 
it is much more important to reduce infections of susceptible individuals than to speed up the recovery of already ill ones.

To investigate the world wide spread of an epidemic in more detail, we now switch to a continuous model. At each node $n$, there is a percentage of infected $j_n$ and susceptible individuals, which is evolved by
\begin{align}
\partial_t j_n &=& \overbrace{\alpha s_n j_n \sigma( j_n / \epsilon)}^{\text{local spread}} &&- \overbrace{\beta j_n}^{\text{recovery}} &+ \overbrace{\sum{\gamma P_mn (j_m - j_n)}}^{\text{network spread}}&\\
\partial_t s_n &=& -\alpha s_n j_n \sigma( j_n / \epsilon)&  &&- \sum{\gamma P_mn (j_m - j_n)}.&
\end{align}
The first term describes how the disease spreads at one location (i.e. proportional to both susceptible and infected individuals, if $j_n > \epsilon$, otherwise zero, as $\sigma$ is a shifted heaviside), the second describes the recovery with rate $\beta$ and the third how infected individuals travel from one node to another. Since each infected was susceptible before, the dgl for the susceptible contains the same terms except the recovery, but with an overall minus sign. The parameters are the infectiousness $\alpha$ and recovery rate $\beta$ which determine the \emph{basic reproductive number} of the disease $R_0= \alpha / \beta$ and the spreading speed $\gamma$. 

For the following simulation, these were chosen to be $R_0 = 1.5$, $\beta = \SI{0.285}{d^{-1}}$ and $\gamma = \SI{2.8e-3}{d^{-1}}$.
The threshold $\epsilon$ was $\num{1e-6}$, and the initial outbreak was set to be in South Africa with $j_{\mathrm{SA}} = \num{1e-3}$. The simuation used Euler integration with a stepsize of \SI{0.05}{d}, running for a total of \SI{300}{d}.

To characterize the spread of the epidemic, the time when there are more than $\epsilon$ infected for the first time, called the \emph{arrival time} $T_A(n) = \mathrm{min}_t \, \sigma(j_n / \epsilon) \neq 0$ of the disease, is determiend for each node. Since the geographical distance has (in this model) no direct influence on how fast a disease can be transmitted from one country to the next, an \emph{effective distance} based on passenger flux is introduced. It is defined by
\begin{align}
	d_{mn} = 1 - \ln (P_mn). \label{eq:epl}
\end{align}

In figure \ref{fig:D1spread}, \textbf{a)} -- \textbf{c)}, the amount of infected individuals $j_n$ is plotted for times $t_1=\SI{50}{d}$, $t_2 = \SI{100}{d}$, and $t_3 = \SI{200}{d}$. Subfigure \textbf{d)} shows the arrival times for all countries.

To find the origin of the outbreak just by using the spread data, we look at the plots of arrival time vs. path length (with respect to effective distance) to a potential outbreak source. 
Ideally, this would yield a linear relation for the actual outbreak source, and no correlation at all for any other country. In practice, the graphs of neighbouring countries look alike. 
Furthermore, the linearity between distance and time is only a trend, the data contain a lot of fluctuations.
Still, this allows to restrict the possible outbreak sources to a few countries. One could then look which one is most closely neighboured to the other possible source countries to find the most likely origin candidate.

In the simulated presented here, it is easily possible to determine that out of South Africa, Peru, and Indonesia, only South Africa can be the epidemic's origin, as shown by figure \ref{fig:arrival}. The linear relation is not as good as in the paper \footnote{D. Brockmann, D. Helbing (2013): The Hidden Geometry of Complex, Network-Driven Contagion Phenomena.}, which can probabliy be attributed to the lower resolution (on country level, highly discretized passenger flux) of the data used to generate the plots.

\begin{figure}
    \centering
    \def\svgwidth{0.9\textwidth}
    \input{D1_.pdf_tex}
    \caption{Initial state of a $N=50, k=3$ Barabasi-Albert network with a single infected individual, and time developmen according to the discrete SIR model describen in section \ref{sec:eponnet}. In this example, all but one node have been infected during the spread of the disease. The last remaining node can no longer be infected, because all of its neighbours are already recovered.}
    \label{fig:D11}
\end{figure}


\begin{figure}
    \centering
    \def\svgwidth{1.0\textwidth}
    \input{D1_illness.pdf_tex}
    \caption{Spread of an edpidemic originating from South Africa (marked with a white cross) on a network of countries connected by airlines. The figures \textbf{a)}, \textbf{b)} and \textbf{c)} show the time development of the percentage of infected individuals (color code: red - high infection, blue - low infection} as snapshots for $t=\SI{50}{d}, t=\SI{100}{d}$ and $t=\SI{200}{d}$, when all countries that were infected during the first 50 days have already recovered.
		In \textbf{d)}, the first time when the illness reached a country (i.e. the number of infected individuals exceeds $\epsilon$, so that the infection can spread inside the country on its own) is visualized, blue denoting early and red denoting late arrival. 
    \label{fig:D1spread}
\end{figure}

\begin{figure}
    \centering
    \gnuplotloadfile[terminal=epslatex, terminaloptions={color size 5,2.0}]{evint.plt}
    \caption{Percentage of nodes that were infected at some time during the disease spread, 
		depending on the contagiosity $\beta$ for different recovery rates $\gamma$. Note that 
		even instant recovery $\gamma=1$ cannot prevent the spread of extremly contagious diseases
		in this model, because a node cannot recover in the same timestep it was infected.}
    \label{fig:D12}
\end{figure}

\begin{figure}
    \centering
    \gnuplotloadfile[terminal=epslatex, terminaloptions={color size 6.35,3.0}]{arrival.plt}
    \caption{Arrival time of the illness plotted against the effective path (as per eqn. \ref{eq:epl}) length between 
		a potential country of origin and the node. For the actual origin (South Africa), a correlation is visible, whereas the other two graphs show no correlation. One problem of the simulation that is clearly visible is the low resolution of the network data, both spatially (i.e. USA and Switzerland are both represented by a single node) and in connection resolution (discretization on x axis is clearly visible).}
    \label{fig:arrival}
\end{figure}

\clearpage
\section{Inferring Network Structure}
The phrase \enquote{if you want to understand function, study structure}
uttered by Francis Crick is a common credo in biochemistry, applied
successfully to analyze and understand the function of large molecules. For
networks too, their structure, meaning the topology and the weigth
distributions, determine what the network can and can't do. This section's
task is to reverse this idea in a certain way: What can be deduced about
the structure of a network when having access to (some of) the output it
produces?

\subsection{Reconstructing Small Networks with Kuramoto Dynamics}
The approach used in order to reconstruct networks with oscillatory
Kuramoto dynamics can be found in the uploaded instruction and the
formulation of the task. The notation used in the following also coincides
with the notation of the instruction, if not introduced elsewise. The
pseudo inverse matrix was calculated with the function
\texttt{numpy.linalg.pinv()} provided by the \texttt{numpy} library.
The most important remarks regarding the simulation and the obtained
results are:
\begin{itemize}
    \item The integration time step for the Euler integration of the
        Kuramoto dynamic was $\dif t = 0.01$.
    \item Linearly spaced values $(T\ix{i})\ix{i=0}\Ix{M+2} \subset [0,
        T\ix{max}]$ were used as sample times. $M+2$ sample times had to be
        used in order to calculate the approximate derivatives for the border values. 
    \item The quality of the reconstructed adjacency matrix $\bar{K}$
        compared to the original matrix $K$ was measured by the quantity $Q_{95}$
        that was also used in a figure of the handout. It is defined
        in the publication of M. Timme and J. Casadiego, J. Phys. A: Math.
        Theor. 47 343001 (2014).
    \item The quality measures $\bar{Q}_{95}$ given below for one set $(N,
        M, T\ix{max})$ of parameters are the averaged $Q_{95}$ values for
        10000 trials.
\end{itemize}

The obtained results for different combinations of $(N, M, T\ix{max})$ are
presented and visualized in figure \ref{fig:D211}. The reconstructions
obtained for $N = 5$ have a good quality that is confirmed by both the high
$Q_{95}$ values and the given visualizations, where the difference networks
have few and thin edges. As expected, higher values of $M$ potentially
increase the quality while lower values decrease it.

The reconstruction quality is visibly worse for $N = 10$ while the values
of $Q_{95} \approx 0.40$ for $M = 100$ and $T = 2$ as well as
$Q_{95}\approx 0.8$ for $M = 200$ and $T = 4$ again indicate that more
measurements improve the result visibly.


\subsection{Reconstructing Larger Networks}
When trying to reconstruct larger networks, the applied method in the
considered parameter space seems to get increasingly unsuitable. While for
$N=12$ and  $M = 100, T\ix{max} = 2$ the average quality was around
$\bar{Q}_{95}\approx 0.35$ it dropped to values lower then $0.3$ for even
higher $N$. One can, however, apparently increase the reconstruction
quality by taking more measurements (possibly over a longer period of
time): For example, $N=12, M=200$, and $T\ix{max}=4$ yields
$\bar{Q}_{95}\approx 0.59$. Nevertheless, the quality could not be
arbitrarily improved with higher values for $M$ and/or $T\ix{max}$ in our
attempts and in fact never really got much higher than $0.6$.  
% N = 5, T = 2, M = 100 -> Q_ = 0.94
% N = 5, T = 4, M = 150 -> Q_ = 0.96
% N = 5, T = 3, M = 50  -> Q_ = 0.92

% N = 10, 


\begin{figure}
    \centering
    \def\svgwidth{0.75\textwidth}
    \input{D211.pdf_tex}
    \caption{Reconstruction of oscillating networks with Kuramoto dynamics. The
        value $Q_{95}$ denotes the quality of the trial depicted in the
        respective row, while $\bar{Q}_{95}$ is the quality of 10000
        trials with the same $N, T$, and $M$ averaged. The line widths of
        the edges are proportional to the respective weights and the
        difference graph (last column) was obtained by taking the
        difference $|\omega\ix{orig} - \omega\ix{rec}|$ as weight matrix.}
    \label{fig:D211}
\end{figure}


%The dependencies of the reconstruction quality $Q_{95}$ on the parameters $N, M,$ and
%$T\ix{max}$ are presented in figures \ref{fig:??} to \ref{fig:??}.

%\paragraph{Dependency on $N$:}
%\paragraph{Dependency on $M$:}
%\paragraph{Dependency on $T\ix{max}$:}

\clearpage
\setcounter{section}{3}
\section{Continuative Topics}
\subsection{Balance in Social Networks}
In the following the \emph{social balance model} with \emph{local triad
dynamics} (described on the handout for D4.1) with $p = 1/3$ is applied on
a network that supposedly represents the family structure of Romeo's and
Juliet's families, presented in figure \ref{fig:D41} (a).  (According to
our research, Juliet has no living siblings at the time the drama takes
place, and Romeo never had siblings at all.)

Some exemplary simulation results are given in figure \ref{fig:D41} (b),
(c), and (d).
An obvious and quite frequent result was the one depicted in figure \ref{fig:D41}
(b), meaning that Romeo and Juliet turned into foes while the family
internals remained untouched.  One could also observe that the family
structures got broken up and mixed sometimes, building two new fractions
(figure \ref{fig:D41} (c)). An event that was very rare (see the results for
$P\ix{paradies}$ below) was the complete conciliation of all persons,
figure \ref{fig:D41} (d).

Having applied the local triad algorithm with $p = 1/3$ for $10000$ trials
yielded that the probability $P\ix{love}$ of Romeo and Juliet still being together after
the social balance has been established is $P\ix{love} = 0.2488\%$.
The probability of paradise, $P\ix{paradies}$, was $P\ix{paradies} = 0.0013$.

The dependency of $P\ix{love}$ and $P\ix{paradies}$ on the pattern
selection probability $p$ is shown in figure \ref{fig:D412}. One can
see that the both probabilities increase with increasing $p$, which is
of course expected.

\subsection{Chimera States}
In a network that consists of identical, non-locally coupled oszillators, it is possible 
that a part of the oszillators will become phase locked while the others remain uncorrelated.
The resulting state is called a \emph{chimera state}.

It can be generated e.g. by a coupling kernel 
\begin{align}
K(\Delta) = (1 + A \cos{\Delta}) / (2 \pi),
\end{align}
such that the whole dynamics is (in a continuum limit of infinitely many oszillators $\theta(x)$)
\begin{align}
 \frac{\partial \theta(x, t)}{\partial t} = - \int_{-\pi}^{\pi} K(x-x^\prime) \sin \left( \theta(x, t) - \theta(x^\prime, t) + \alpha \right) \, \mathrm{d} x^\prime. \label{eq:contdyn}
\end{align}

To work with this numerically, the continuous variable $\theta(x, t)$ is replaced by finitely many (256) oszillators, such that the integral eq. \ref{eq:contdyn} becomes a sum. The parameter $A$ was set to $A= 0.995$ and $\alpha = \pi/2 - 0.18$. As initial conditions, each oszillator was given a random phase. 
The development of the system for $t=0$ to $t=80$ can be seen in fig. \ref{}.
In some spatial region, the initially uncoordinated oszillators become phase locked, whereas elsewhere they continue to move uncorrelated: The system has entered a chimera state.

To quantify this statement, the complex order parameter is calculated, which is given by (in a continuum system)
\begin{align}
 O(x, t) = \int_{-\pi}^{\pi} K(x-x^\prime) \exp( \theta(x^\prime, t)) \, \mathrm{d} x^\prime. \label{eq:orderparameter}
\end{align} 
From this we can extract the local phase coherence $R = |O|$ and the local avergage phase $\Theta = \mathrm{arg}(O)$, such that
$O = R(x) \exp( i \Theta(x, t) )$. 
These values can be seen in fig. \ref{}, which demonstrate that the phase coherence in the unordered region is very low, but relatively high in the ordered region, as expected. 
The transition from unordered to ordered is much smoother than the phase plots would suggest on a first glance.
However, in the phase plots it is already visible that the boundary oszillators of the phase locked region have a slightly different frequency than the one in the middle, indicating that the synchronization is less good, in accordance with the quantitative measurement.

\subsection{Page Rank}
One of the most iconic modern examples for a network is the Internet, 
where hyperlinks connect webpages that are identified 
by a unique URL, which constitute the nodes of the network (This is of course
an oversimplification considering modern webpages which are hardly a static 
html document, and often contain java script to dynamically load content. For
the task at hand -- ranking based on a given connection graph -- this does not
matter, but a fully fledges search engine has to account for that).

The enormous wealth of information on the Internet has to be ranked according
to its relevance if one wants to be able to use it. One such ordering algorithm 
is \emph{Page Rank}, which is based purely on topology (i.e. it does not use 
any semantic information). This algorithm calculates the stationar probability 
distribution $\vec{x}$ of a random walk on the network with two additional properties:
\begin{itemize}
 \item To prevent trapping in dangling nodes, the walker jumps from a dangling node
		to all other nodes with equal probability.
 \item To prevent loops, the walker has the probabiltiy $1-\alpha$ of jumping to a random	
	node in any step.
\end{itemize}

This can be approximated by the iterative update rule
\begin{align}
	\vec{x}_{k+1} = \alpha P^\mathrm{T} \vec{x}_k + \left(\alpha \vec{x}_k \cdot \vec{a} + (1 - \alpha) \right) \vec{e}/N,
\end{align}
where $\vec{a}$ is a vector that is one for every dangling node, $\vec{e}$ has one in each entry, $P$ is the
adjacency matrix and $N$ the number of nodes.



\begin{figure}
    \centering
    \def\svgwidth{0.9\textwidth}
    \input{D41.pdf_tex}
    \caption{Depiction of some typical situations (b, c, d) that arise when
        balancing the original Romeo and Juliet graph (a). The red nodes
        represent Juliet's family (including Juliet herself, marked by J.) and
        the blue nodes consist of Romeo's family (Romeo being marked by
        R.). If an edge is depicted, the corresponding persons are friends;
        if an edge is missing the two corresponding persons are foes. The
        colors of the edges in situation (c) mark the two disjoint fully
        connected components that emerge.}
    \label{fig:D41}
\end{figure}

\begin{figure}
    \centering
    \gnuplotloadfile[terminal=epslatex, terminaloptions={color size 5,2.5}]{pictures/D41.gp}
    \caption{Relative number of \enquote{Love} (Romeo and Juliet end up
    together) or \enquote{Paradies} (all family members of both families
    are friends) outcomes in dependence of the parameter $p$. For values of $p > 0.5$ nearly all
    \enquote{Love} endings were also \enquote{Paradies} endings.}
    \label{fig:D412}
\end{figure}



\end{document}

